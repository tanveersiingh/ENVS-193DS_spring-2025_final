---
title: "final"
format: html
editor: visual
---

# Github link

[Github Repository](https://github.com/tanveersiingh/ENVS-193DS_spring-2025_final.git)

# Set up

```{r}
# load packages
library(tidyverse) 
library(here) 
library(flextable) 
library(janitor) 
library(officer) 
library(dplyr)
library(lubridate)
library(DHARMa)
library(MuMIn)
library(ggeffects)
# read in data
sst <- read_csv("./data/SST_update2023.csv")
nest_boxes <- read_csv("./data/occdist.csv")
```

# Problem 1. Research writing

## a. Transparent statistical methods

In part 1, they used a Pearson correlation test.In part 2, they used a one way ANOVA test.

## b. More information needed

The one-way ANOVA shows that at least one source differs in average nitrogen load, but not which one(s). I recommend adding a Tukey's HSD post hoc test to determine which specific source pairs differ significantly. Additionally, although p = 0.02 indicates statistical significance, it does not show the magnitude of those differences. To address this, I suggest calculating Cohen’s d to quantify the effect size between each pair of sources, indicating whether differences are small, medium, or large.

## c. Suggestions for rewriting

Biological narrative: Average nitrogen load (kg year$^{-1}$) differs among sources, with urban land contributing notably higher nitrogen levels compared to grasslands, suggesting source-specific impacts on nitrogen pollution. Statistical summary: We rejected the null hypothesis that there is no difference in average nitrogen load (kg year$^{-1}$) among sources (urban land, atmospheric deposition, fertilizer, wastewater treatment, and grasslands). We found a small/medium/large effect size ($\eta^2$ = effect size) using a one-way ANOVA (F(df$_1$, df$_2$) = F-statistic, p = 0.02, $\alpha$ = significance level). On average, Source A has a higher/lower nitrogen load than Source B (difference between groups, 95% CI: \[lower, upper\] kg year$^{-1}$).

# Problem 2. Data visualization

## a. Cleaning and summarizing

```{r}
sst_clean <- sst |> # start with df
  mutate( # use mutate the create year and month from date
    year = year(date), # create year column
    month = month(date, label = TRUE, abbr = TRUE) # create month column with the abbreviations 
  ) |>
  filter(year >= 2018 & year <= 2023) |> # selecting only years 2018 - 2023
  mutate(year = as.factor(year)) |> # change year column to factor
  group_by(year, month) |> # grouping year and month for summary calculations
  summarize(mean_monthly_sst = round(mean(temp, na.rm = TRUE), 1)) # summarize and round mean_monthly_sst

print(slice_sample(sst_clean, n = 5)) # slice and print 5 random rows
print(str(sst_clean)) # print the structure of sst_clean
```

## b. Visualize the data

```{r}
ggplot(sst_clean, # start with clean dataset
       aes(x = month, # month on x
           y = mean_monthly_sst, # mean monthly sst on y
           color = year, # group by color
           group = year)) + # group by color
  geom_point() + # add points
  geom_line() + # connect with line
  scale_color_manual( # add manual color gradient
    values = c(
      "2018" = "mistyrose",
      "2019" = "lightcoral",
      "2020" = "indianred",
      "2021" = "firebrick",
      "2022" = "red",
      "2023" = "darkred")) +
  ylim(NA, 20) + # get y limit
  labs( # rename labels
    x = "Month", 
    y = "Mean monthly sea surface temperature (°C)", 
    color = "Year") + 
  theme_bw() + # add theme
  theme( # clean up the lines from the theme in the background
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    plot.background = element_rect(fill = "white"),
    panel.background = element_rect(fill = "white"),
    legend.position = c(0.10, 0.70)) # change legend position
```

# Problem 3. Data analysis

```{r}
nest_boxes_clean <- nest_boxes |> # start with original df
  clean_names() |> # clean column names
  select(box_occupant, season, edge_distance, sp, cs, e, tm) |> # select these columns
  mutate(season = as.factor(season)) # change season to factor.
```

## a. Response variable

In this experiment, nest box occupancy was recorded as a binary variable: 1 indicated a nest box was occupied by the species, and 0 indicated it was unoccupied.

## b. Purpose of study

The main difference is that Swift Parrots are the target species for the study and only use the nest boxes during the breeding season. Common Starlings and Tree Martins are non target competitors who more consistently occupy the nest boxes over time.

## c. Difference in “seasons”

The two "seasons" compared are in 2016 (when the nest boxes were deployed) and 2019 (after three years of deployment of nest boxes).

## d. Table of models

| Model Number | Box Occupancy | Season | Distance to Forest Edge | Model Description |
|:-----------:|:-----------:|:-----------:|:-----------:|:----------------------|
| 0 | X |  |  | Null model |
| 1 | X | X | X | Saturated model |
| 2 | X | X |  | Season only model |
| 3 | X |  | X | Distance to forest edge only model |

## e. Run the models

```{r}
# run model
model0 <- glm(
  sp ~ 1, # formula
  data = nest_boxes_clean, # data frame
  family = "binomial"
)

model1 <- glm(
  sp ~ season + edge_distance, # formula
  data = nest_boxes_clean, # data frame
  family = "binomial"
)

model2 <- glm(
  sp ~ season, # formula
  data = nest_boxes_clean, # data frame
  family = "binomial"
)

model3 <- glm(
  sp ~ edge_distance, # formula
  data = nest_boxes_clean, # data frame
  family = "binomial")
```

## f. Check the diagnostics

```{r}
# Plot diagnostic residuals for model0 to assess model fit
plot(simulateResiduals(model0))

# Plot diagnostic residuals for model1 to assess model fit
plot(simulateResiduals(model1))

# Plot diagnostic residuals for model2 to assess model fit
plot(simulateResiduals(model2))

# Plot diagnostic residuals for model3 to assess model fit
plot(simulateResiduals(model3))
```

## g. Select the best model

```{r}
AICc(model1, # best model
     model2,
     model3) |>
     arrange(AICc)
```

The best model, as determined by Akaike’s Information Criterion (AIC), was the model that included both season and distance to forest edge as predictors. This model had the lowest AIC value, indicating the best balance between model fit and complexity for explaining Swift Parrot nest box occupancy.

## h. Visualize the model predictions

```{r}
# Generate predicted values from model1 across edge_distance from 0 to 1100 by 10 meters, for each season
prediction <- ggpredict(model1, terms = c("edge_distance [0:1100 by=10]", "season"))

# Create a ggplot object using the predictions
ggplot(prediction,
       aes(x = x, # x = edge_distance
           y = predicted, # y = predicted occupancy
           color = group)) + # color by season (group)
  geom_line(linewidth = 1) + # add line
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high, fill = group), alpha = 0.35) + # add ribbon for CI
  geom_jitter(data = nest_boxes_clean, aes(x = edge_distance, y = sp, color = season), # add jittered data
              width = 0, height = .5, alpha = 0.4, inherit.aes = FALSE) + # no jittered width, add transparency
  ylim(0, 1) + # y limit range
  labs(
    x = "Distance from Forest Edge (m)", # x label 
    y = "Probability of Swift Parrot Occupancy", # y label
    color = "Season",
    fill = "Season") +
  theme_bw() + # add theme
  theme(panel.grid = element_blank()) + # no grid
  scale_color_manual(values = c("2016" = "darkblue", "2019" = "seagreen")) + # add color
  scale_fill_manual(values = c("2016" = "darkblue", "2019" = "seagreen")) # add color

```

## i. Write a caption for your figure

Figure 1. Predicted probability of Swift Parrot occupancy in relation to distance from forest edge, by season (2016 and 2019). Shaded ribbons represent 95% confidence intervals. Raw data points are jittered for visibility.

## j. Calculate model predictions

```{r}
model1_predictions <- ggpredict(
  model1,
  terms = c("edge_distance [0,900]", "season"))

print(model1_predictions)
```

## k. Interpret your results

In both the 2016 and 2019 seasons, my analysis revealed a clear and consistent trend in Swift Parrot nest box occupancy relative to distance from the forest edge. In both years, the probability of occupancy peaked at the forest boundary (0 m) and declined sharply with increasing distance into the open landscape. In 2016, the estimated occupancy probability was 0.48 (95% CI: 0.33–0.64) at 0 m and dropped to 0.12 (95% CI: 0.06–0.24) by 900 m. In 2019, occupancy at the edge was lower at 0.06 (95% CI: 0.03–0.13), but remained higher at 900 m at 0.30 (95% CI: 0.18–0.44). This negative association suggests that Swift Parrots prefer nest boxes situated closer to forested areas. Biologically, this pattern may reflect the species’ reliance on forest resources for foraging, shelter, or protection from predators.

# Problem 4. Affective and exploratory visualizations

## a. Comparing visualizations

I changed the topic of my personal data project after homework 2, so the data does not represent the same experiment. I will use the data visualization I made in homework 3 to compare against my affective visualization.

In the exportatory visualization, I used a box plot to show to pages per minute that I read at each location. In my affective visualization, I was able to show more variables such as total time reading, total pages read, number of distractions, and comprehension.

The only similarity I see within both of my visualizations are the locations. I was not able to represent variables from my affective visualization in the boxplot. Similarly, I did not know how to represent pages per minute from my affective visualization.

Between both my visualizations, I see that I read more efficiently when on my balcony. The box plot showed it with the higher median and in my affective visualization with the consistent thickness, height, and color of the book.

During week 9 workshop, Ellie and Eliana gave me great advice on my affective visualization. They liked my idea, but said that the jar of marbles was a misleading representation of my experiment. They said it would make more sense if I used a bookshelf and placed books instead of marbles. This works better because when you initially see the visualization, you immediately think of something related to reading, unlike the jar of marbles.
